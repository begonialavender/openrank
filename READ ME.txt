============================================================================================================================														
											听涛————百度贴吧舆情分析助手
============================================================================================================================
团队分工：
	组长田朴序：程序代码实现、数据获取
	组员刘宇轩：PPT、演示视频、数据报告
============================================================================================================================
项目结构如下：
openrank/
├── config.py                           # 配置文件
├── docker-compose.yml                  # Docker配置
├── main.py              				# 主程序（完整流程）
├── README.md                           # 项目说明
|—— 数据备份.zip                         # 编辑好的一份用户数据
│
├── maxkb_manager/                      # MaxKB客户端模块
│   ├── __init__.py                     # 模块导出
│   ├── deploy.py                       # Docker部署
│   ├── api_client.py                   # 管理员客户端（文档上传）
│   └── jwt_client_fixed.py             # 聊天客户端
├── spider/                             # 爬虫模块
│   ├── __init__.py
│   └── tieba_spider.py                 # 贴吧爬虫
│
├── data_processor/                     # 数据处理模块
│   ├── __init__.py
│   ├── cleaner.py                      # 数据清洗
│   └── txt_converter.py                # 格式转换
│
└── data/                               # 数据目录（自动生成）
    ├── raw/                            # 原始爬取数据
    ├── cleaned/                        # 清洗后数据
    └── maxkb_docs/                     # MaxKB格式文档
============================================================================================================================

一、部署maxkb
	1.安装maxkb之前的准备工作：
		下载安装docker desktop并安装。安装完成之后重启电脑并打开。这是使用maxkb需要的环境。
	2.部署maxkb：
		在maxkb官网上部署maxkbv2，最好使用在线部署。官方下载说明网站：https://maxkb.cn/docs/v2/installation/online_installtion/
	3.maxkb上接入大模型：
		下载之后在本地浏览器打开maxkb，接入deepseek-reasoner模型。

二、修改maxkb配置
	将maxkb下载文件里面的data文件夹路径放到docker-compose文件的这个位置，可以备份数据：
		volumes:
      		# 持久化数据卷
      		- ./（任意路径）:/opt/maxkb
	或者在docker desktop里面找到当前容器的/opt/maxkb下载。若无备份，则每次关闭maxkb后其上的数据均丢失。
	如果改了maxkb启动端口，需要在docker-compose文件的这个位置修改端口：
		ports:
    		- "8080:8080" # 将本地8080端口映射到容器的8080端口
		
三、初始化maxkb
	本文件夹里自带了一份maxkb用户数据在数据备份.zip下。查阅官方关于备份说明即可使用：https://maxkb.cn/docs/v2/installation/backup
	如果使用自己的本地maxkb账号数据，则需在config文件里如下配置来连接：
		1.用户名密码：
			# ======【管理后台认证】=====
			"admin": {
				"username": "",
				"password": "",
				"workspace": "default"  # 默认工作空间
			},
		2.知识库id（从知识库详情页URL获取）：
			# ======【知识库配置】=====
			"knowledge_base_id": "",
		3.应用id与key（从应用概览界面获取）：
			# ======【应用配置】=====
			"application": {
				"id": "",  # 应用ID
				"name": "",
				"api_key": ""  # 应用API密钥
			},
		4.其他设置均在config与docker-compose里修改。

四、环境配置
	1. HTTP请求与异步核心（版本锁定，确保兼容）：
		aiohttp==3.9.5  
		requests>=2.31.0
	2. 网页爬虫与解析（核心依赖，版本严格锁定）：
		requests-html==0.10.0  
		beautifulsoup4>=4.12.0
		lxml>=4.9.0
		fake-useragent>=1.4.0
	3. 数据处理：
		pandas>=2.2.0, <3.0.0  
		numpy>=1.24.0
	4. 系统与工具：
		pathlib>=1.0.1
		python：>=3.8

五、使用
	运行main程序即可。确保其他程序路径按照本文开头结构存放。
	程序运行流程如下：
		1.询问并获取用户想要分析的贴吧名称，然后运行爬虫模块爬取内容。
		2.将获得的信息保存并转换成maxkb支持的格式。
		3.将转换后的文件上传maxkb知识库。
		4.调用maxkb的智能体进行问答。
		5.在各个程序间夹有测试运行的部分，如有错误会输出。

六、技术难点说明
	1.百度贴吧网站有严格的反爬虫机制，爬虫模块解决了动态验证，绕过了反爬。
	2.在maxkb页面推导出url结构、必须的参数，并成功找到知识库接口，使文件上传maxkb知识库。
	3.成功推导出智能体的url，使程序成功对接。

